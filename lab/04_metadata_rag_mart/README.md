# Lab 04: Metadata-Driven RAG with Governed Data Mart Provisioning

**Conference demo for: "pgvector: Why is PostgreSQL at the center of AI workflows?"**

## The Problem

Data lakes are great for storing massive amounts of data cheaply (Parquet on S3). But they're awful for exploratory queries â€” no indexes, no JOINs, no governance. BI analysts wait 10+ minutes for queries, BI connectors time out, and every new KPI requires a data engineering ticket.

## The Solution: Right Tool for the Right Job

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 3: Broker Intelligence (Senior Portfolio Manager)            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚  â€¢ Scans: financial news, filings, analyst recs, earnings reports  â”‚
â”‚  â€¢ Cross-references signals with client position metadata          â”‚
â”‚  â€¢ Detects: overexposure, sector risk, analyst downgrades          â”‚
â”‚  â€¢ Presents alerts to human (human-in-the-loop)                   â”‚
â”‚  â€¢ On approval â†’ triggers Agent 1 + Agent 2 pipeline              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ approved alert + question
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 1: RAG Search                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  â€¢ Embeds question (Voyage finance-2, input_type="query")         â”‚
â”‚  â€¢ Searches pgvector metadata catalog (1024d DiskANN)             â”‚
â”‚  â€¢ Returns: tables, columns, joins, KPI patterns                  â”‚
â”‚  â€¢ NEVER touches raw data â€” only metadata + embeddings            â”‚
â”‚  â€¢ Logs search to rag_monitor for quality tracking                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ recommendation
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 2: Pipeline                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  1. Reads Parquet from S3 (MinIO) â†’ stages into lake.* in PG     â”‚
â”‚  2. Generates CREATE TABLE AS SELECT (LLM)                        â”‚
â”‚  3. Applies PII masking (governance.mask_name/mask_account)       â”‚
â”‚  4. Creates data_mart.dm_xxx with governed access                 â”‚
â”‚  5. Drops staging tables (ephemeral)                              â”‚
â”‚  6. Logs audit trail + registers mart                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL 18 â€” Governed Data Mart                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  â€¢ Fast JOINs, indexes, aggregations                              â”‚
â”‚  â€¢ Role-based access (classification â†’ grants)                    â”‚
â”‚  â€¢ PII masking enforced at SQL level                              â”‚
â”‚  â€¢ Full audit trail for regulatory compliance                     â”‚
â”‚  â€¢ BI analyst queries in seconds, not minutes                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The key insight:** PostgreSQL at the center â€” it handles metadata catalog (pgvector), governance framework, RAG quality monitoring, AND the final data mart. One database, multiple workloads.

## Infrastructure

| Component | Role | Image |
|-----------|------|-------|
| **PostgreSQL 18** | Metadata catalog + governance + data marts | Custom (Dockerfile.pg18) |
| **pgvector 0.8.1** | Vector data type and operators | Built from source |
| **pgvectorscale 0.9.0** | StreamingDiskANN indexes for production scale | Built from source (Timescale) |
| **MinIO** | S3-compatible object storage (data lake) | `minio/minio:latest` |

## Data Lake (Parquet on S3)

The data lake simulates a Swiss private bank trading system:

| File | Rows | Description |
|------|------|-------------|
| `exchanges.parquet` | 8 | ISO 10383 MIC codes |
| `instruments.parquet` | 34 | Swiss blue chips, EU/US equities, bonds, ETFs |
| `counterparties.parquet` | 6 | Brokers, custodians, clearing houses |
| `clients.parquet` | 25 | Swiss/EU/intl mix incl. PEPs |
| `accounts.parquet` | 63 | Trading, custody, cash |
| `orders.parquet` | ~515 | FIX-protocol order book |
| `executions.parquet` | ~668 | Fills with TCA data |
| `positions.parquet` | ~358 | EOD snapshot with P&L |
| `market_prices.parquet` | ~1,000 | 30-day OHLCV |
| `risk_limits.parquet` | ~75 | Exposure/concentration limits |
| `risk_metrics.parquet` | 125 | VaR, CVaR, Sharpe per client |
| `compliance_checks.parquet` | ~1,040 | Pre-trade checks |
| `aml_alerts.parquet` | 15 | AML investigation pipeline |
| `financial_news.parquet` | ~200 | Bloomberg/Reuters/AWP financial news |
| `public_filings.parquet` | ~80 | SIX/FINMA regulatory filings |
| `analyst_recommendations.parquet` | ~150 | Sell-side analyst research |
| `financial_reports.parquet` | ~60 | Quarterly/annual earnings reports |

**No raw data in PostgreSQL.** PG stores only metadata about structure and meaning.

## Metadata Catalog (pgvector)

Each catalog entry has two enrichment fields that dramatically improve retrieval quality:

- **`detail_bi`** â€” Manual annotation from BI team: business context, refresh cycles, regulatory requirements, caveats
- **`detail_agent`** â€” Auto-generated from data inspection: cardinality, distributions, common values, null rates

These fields are concatenated into `metadata_text` before embedding, producing vectors that capture both schema structure AND business semantics.

## Governance Framework

### Classification â†’ Access Matrix

| Classification | bi_analyst | risk_manager | compliance_officer | portfolio_manager |
|---------------|:---:|:---:|:---:|:---:|
| ğŸŸ¢ public | âœ“ | âœ“ | âœ“ | âœ“ |
| ğŸ”µ internal | âœ“ | âœ“ | âœ“ | âœ“ |
| ğŸŸ  confidential | âœ— | âœ“ | âœ“ | âœ“ |
| ğŸ”´ restricted | âœ— | âœ— | âœ“ | âœ— |

### PII Masking

Applied automatically unless requester is `compliance_officer`:

| Column | Function | Example |
|--------|----------|---------|
| `clients.legal_name` | `governance.mask_name()` | "Dr. Elena Brunner" â†’ "D** E**** B******" |
| `accounts.account_number` | `governance.mask_account()` | "CH9300010001" â†’ "CH93********" |

## RAG Quality Monitoring

Built-in evaluation framework with:

- **Search logging** â€” every query with results, latencies, classifications
- **Golden benchmarks** â€” 16 annotated queries with expected results
- **IR metrics** â€” Precision@K, Recall@K, nDCG@K, MRR, MAP
- **Latency tracking** â€” embedding, search, reasoning breakdown
- **Feedback loop** â€” user relevance feedback for continuous improvement

Run evaluation:
```bash
python python/50_evaluate_rag.py --verbose
```

Query monitoring:
```sql
SELECT * FROM rag_monitor.v_search_quality_trend;
SELECT * FROM rag_monitor.v_feedback_summary;
```

## Quick Start

```bash
# 1. Build and start infrastructure
cd lab/04_metadata_rag_mart/docker
docker compose build          # builds PG 18 + pgvector + pgvectorscale
docker compose up -d
# Wait for healthy:
docker exec lab04_pg18 pg_isready -U dba_admin -d metadata_catalog

# 2. Install Python deps
pip install -r requirements.txt

# 3. Set API keys
export VOYAGE_API_KEY="pa-..."    # Voyage AI (embeddings)
export OPENAI_API_KEY="sk-..."    # OpenAI (LLM reasoning)

# 4. Generate data lake (Parquet â†’ MinIO)
python python/00_generate_parquet.py

# 5. Scan schemas + embed metadata
python python/10_scan_and_embed.py

# 6. Run the demo (3 scenarios)
python python/40_demo.py

# 7. Run broker intelligence demo
python python/45_demo_broker.py --approve-all

# 8. Evaluate RAG quality
python python/50_evaluate_rag.py --verbose

# Optional: single scenario or dry-run
python python/40_demo.py --scenario 1
python python/40_demo.py --dry-run
python python/45_demo_broker.py --approve 1 --dry-run
```

## Demo Scenarios

### Agent 1 + Agent 2 Pipeline (40_demo.py)

**S1: Portfolio Exposure Dashboard (BI Analyst)**
â†’ ğŸ”µ internal | PII masked | All roles access

**S2: Risk Limit Monitoring (Risk Manager)**
â†’ ğŸŸ  confidential | PII masked | risk_manager + compliance only

**S3: AML Investigation View (Compliance Officer)**
â†’ ğŸ”´ restricted | Full PII (compliance privilege) | compliance only

### Agent 3 Broker Intelligence (45_demo_broker.py)

**S-Broker-1: NestlÃ© Revenue Miss + Consumer Staples Overexposure**
â†’ Signal: NestlÃ© Q4 revenue misses by 2.3% â†’ ğŸ”´ critical alert
â†’ Action: Provision dm_nestle_exposure_impact with sector + client breakdown

**S-Broker-2: FINMA Regulatory Action on UBS + Financials Concentration**
â†’ Signal: FINMA orders UBS to increase capital buffer â†’ ğŸ”´ critical alert
â†’ Action: Provision dm_financials_sector_risk with concentration analysis

**S-Broker-3: Multiple Analyst Downgrades in Tech Sector**
â†’ Signal: Goldman downgrades NVIDIA, JP Morgan cuts ASML â†’ ğŸŸ  warning alerts
â†’ Action: Provision dm_tech_downgrade_impact with P&L impact

## Technical Notes

- **Embedding:** Voyage AI `voyage-finance-2` (1024d, finance-optimized, +7% vs OpenAI)
  - Asymmetric search: `input_type="document"` for catalog, `input_type="query"` for questions
- **Chat/DDL:** OpenAI gpt-5.2 (Agent 2), gpt-5-mini (Agent 1 reasoning)
- **Vector index:** StreamingDiskANN (pgvectorscale) â€” production-grade ANN
- **Data seed:** 42 (fully reproducible)

### Environment Variables

```bash
export VOYAGE_API_KEY="pa-..."       # embeddings
export OPENAI_API_KEY="sk-..."       # LLM chat
export S3_ENDPOINT="http://localhost:9000"    # MinIO (default)
export DB_HOST="localhost"                     # PG (default)
export DB_PORT="5433"                          # PG (default)
```

## File Structure

```
lab/04_metadata_rag_mart/
â”œâ”€â”€ README.md
â”œâ”€â”€ SKELETON-lab04.md              # reference doc (original design)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.pg18              # PG 18 + pgvector + pgvectorscale
â”‚   â””â”€â”€ docker-compose.yml           # PG + MinIO
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 00_extensions.sql            # vector, vectorscale, pgcrypto
â”‚   â”œâ”€â”€ 01_metadata_catalog.sql      # pgvector catalog (detail_bi/detail_agent)
â”‚   â”œâ”€â”€ 02_governance.sql            # roles, audit, masking, registry
â”‚   â””â”€â”€ 03_rag_monitoring.sql        # search logs, judgments, evaluations
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ config.py                    # shared configuration
â”‚   â”œâ”€â”€ 00_generate_parquet.py       # â†’ Parquet â†’ MinIO (18 tables)
â”‚   â”œâ”€â”€ 10_scan_and_embed.py         # Parquet schemas â†’ pgvector catalog
â”‚   â”œâ”€â”€ 20_agent_rag_search.py       # Agent 1: RAG metadata search
â”‚   â”œâ”€â”€ 30_agent_pipeline.py         # Agent 2: Parquet â†’ PG data mart
â”‚   â”œâ”€â”€ 35_agent_broker.py           # Agent 3: Broker intelligence
â”‚   â”œâ”€â”€ 40_demo.py                   # demo orchestrator (3 scenarios)
â”‚   â”œâ”€â”€ 45_demo_broker.py            # broker intelligence demo
â”‚   â”œâ”€â”€ 50_evaluate_rag.py           # RAG quality evaluation
â”‚   â””â”€â”€ test_no_api.py               # full test without API keys
â””â”€â”€ benchmarks/
    â””â”€â”€ golden_queries.json          # 16 annotated benchmark queries
```

## Connection to Presentation

**Slide 29 (Before):** Manual SQL queries â†’ 10 min, BI connector timeouts
**Slide 30 (After):** This lab â€” user asks in natural language, RAG searches metadata, Pipeline Agent provisions governed data mart in seconds

**Why PostgreSQL at the center:**
1. **pgvector** â€” metadata search (no sensitive data exposure)
2. **Governance** â€” audit trail, masking, RLS in SQL
3. **Data mart** â€” fast JOINs, indexes for BI queries
4. **Monitoring** â€” RAG quality metrics in the same DB
5. **One database** â€” metadata, governance, monitoring, compute
